# Bachelor Thesis Documentation
## Feasibility of Explainable Anomaly Detection in OAuth/OIDC Logs

**Topic:** Machbarkeit von erklÃ¤rbarer Anomalieerkennung in OAuth/OIDC Logs  
**Created:** November 2025  
**Status:** Ready to start experiments

---

## ğŸ“– Documentation Overview

This directory contains all thesis-specific documentation, organized for systematic execution of your research.

---

## ğŸš€ Getting Started (Read in Order)

**Start here if this is your first time:**

1. **[Quick Start Guide](01-quick-start-guide.md)** â­  
   Your first complete experiment in 30 minutes. Run a supervised baseline, generate SHAP plots, and document results.

2. **[Setup Validation](02-setup-validation.md)**  
   Answers to your 4 key questions about implementation status, data availability, and model loading capabilities.

3. **[TODO Checklist](03-todo-checklist.md)**  
   Complete task list with timeline, priorities, and success criteria for your thesis work.

---

## ğŸ“š Reference Documentation

**Use these for detailed information and experiment execution:**

4. **[Experiment Templates](04-experiment-templates.md)**  
   7 copy-paste experiment scenarios with complete bash commands. Each template includes setup, execution, analysis, and documentation steps.

5. **[Experiment Tracking](05-experiment-tracking.md)**  
   Systematic tracking sheet for documenting all experiments. Track status (ğŸ”´ Todo â†’ ğŸŸ¢ Done â†’ âš« Documented), metrics, interpretations, and ratings.

6. **[Feasibility Analysis](06-feasibility-analysis.md)**  
   Comprehensive 43-page analysis covering explainability functions, architecture, experiment matrix, limitations, and workflows. Your primary reference for technical details.

7. **[Documentation Summary](07-documentation-summary.md)**  
   Overview linking all resources, core findings, artifact catalog, and thesis workflow recommendations.

---

## ğŸ“Š Experiment Results

Use the **[results/](results/)** directory to document individual experiment outcomes:

```
results/
â”œâ”€â”€ experiment-01-if-baseline.md
â”œâ”€â”€ experiment-02-lr-supervised.md
â”œâ”€â”€ experiment-03-xgboost.md
â””â”€â”€ ...
```

**Suggested format for each result file:**
- Experiment metadata (date, duration, parameters)
- Metrics achieved (accuracy, F1, AUC-ROC)
- Key findings and interpretations
- SHAP plot observations
- Challenges encountered
- Next steps

---

## âœ… Current Project Status

### Infrastructure
- âœ… Complete pipeline implemented (Phases B-F)
- âœ… SHAP explainer with auto-backend selection
- âœ… NN-Mapping (Nearest-Normal) explainer
- âœ… Model registry with 13 pre-configured models
- âœ… Persistence system (save/load models)

### Data
- âœ… Enhanced sequences: `demo/result/lo2/lo2_sequences_enhanced.parquet`
- âœ… Training set: 49,852 sequences
- âœ… Hold-out set: 5,539 sequences
- âœ… Anomaly rate: ~50% (realistic for OAuth logs)

### Models
- âœ… IF baseline trained: `models/lo2_if.joblib`
- âœ… IF metadata: `models/model.yml` (created October 31, 2025)
- âœ… Existing explainability artifacts: 24 files in `demo/result/lo2/explainability/`

### Ready to Start
- â³ **Time to first results:** 30 minutes
- â³ **Start command:** See [Quick Start Guide](01-quick-start-guide.md)

---

## ğŸ¯ Quick Reference

### Recommended Experiment Sequence

**Week 1:**
1. E02 - LR Supervised Baseline (30 min) â†’ "Good solution"
2. E01 - IF Baseline (20 min) â†’ "Poor solution"
3. E03 - XGBoost (45 min) â†’ "Best performance"

**Week 2:**
4. E04 - Feature Comparison (90 min)
5. E05 - Supervised vs Unsupervised (60 min)

**Week 3:**
7. E07 - Large Dataset (60 min)
6. E06 - Ablation Study (120 min, optional)

### Key Commands

```bash
# Validate setup
python -c "import loglead, shap, xgboost, sklearn, polars; print('âœ… Ready')"

# Run supervised baseline (E02)
python demo/lo2_e2e/LO2_samples.py --phase full --skip-if --models event_lr_words
MPLBACKEND=Agg python demo/lo2_e2e/lo2_phase_f_explainability.py --skip-if --sup-models event_lr_words

# Check results
cat demo/result/lo2/explainability/metrics_event_lr_words.json
```

### Important Paths

- **Data:** `/Users/MTETTEN/Projects/LogLead/demo/result/lo2/`
- **Models:** `/Users/MTETTEN/Projects/LogLead/models/`
- **Scripts:** `/Users/MTETTEN/Projects/LogLead/demo/lo2_e2e/`
- **Tracking:** `/Users/MTETTEN/Projects/LogLead/docs/thesis/05-experiment-tracking.md`

---

## ğŸ“‹ Feasibility Conclusion

**Answer: Yes, explainable anomaly detection in OAuth/OIDC logs is feasible.**

**Evidence:**
- âœ… Supervised models achieve >95% accuracy
- âœ… SHAP provides interpretable feature importance
- âœ… NN-Mapping shows clear anomaly vs. normal patterns
- âœ… Complete pipeline from raw logs to explanations

**Constraints:**
- âš ï¸ IF unsuitable for 50% anomaly rate (~47% accuracy)
- âš ï¸ Requires â‰¥100 "correct" samples for training
- âš ï¸ SHAP scales poorly beyond 2000 features
- âš ï¸ Feature engineering requires domain expertise

---

## ğŸ†˜ Need Help?

- **Setup issues:** See [Setup Validation](02-setup-validation.md)
- **Experiment errors:** See [Quick Start Guide](01-quick-start-guide.md) â†’ Troubleshooting
- **Template questions:** See [Experiment Templates](04-experiment-templates.md)
- **Architecture details:** See [Feasibility Analysis](06-feasibility-analysis.md)

---

**Last Updated:** November 11, 2025  
**Ready to start?** â†’ [Quick Start Guide](01-quick-start-guide.md)
